%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Large Colored Title Article
% LaTeX Template
% Version 1.1 (25/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% Modified by:
% Julian Kirsch, Nikita Basargin
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[DIV=calc, paper=a4, fontsize=11pt, twocolumn]{scrartcl}

\usepackage{lipsum}
\usepackage[english]{babel}
\usepackage{microtype}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amsfonts,amsthm}
\usepackage{booktabs}
\usepackage{sectsty}
\usepackage{url}
\usepackage{csquotes}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[font=small,format=plain,labelfont=bf,up,textfont=it,up]{caption}

\usepackage{fancyhdr}
\usepackage{lastpage}

\sloppy
\hbadness 10000
\renewcommand*\rmdefault{ppl}\normalfont\upshape
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}
\renewcommand{\UrlFont}{\small\tt}
\allsectionsfont{\color{tumblue}\usefont{OT1}{phv}{b}{n}}

\usepackage[osf, sc]{mathpazo}
\usepackage{helvet}

\definecolor{tumblue}{RGB}{0,101,189}

% https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings
\lstset{
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  frame=single,
  rulecolor=\color{black},
  tabsize=8,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  language=C,
  keywordstyle=\bfseries\color{OliveGreen},
  commentstyle=\itshape\color{Mahogany},
  stringstyle=\color{BrickRed},
  keywordstyle=[2]{\color{Cyan}},
  escapechar=ÃŸ,
  xleftmargin=8pt,
  xrightmargin=3pt,
  basicstyle=\scriptsize,
  morekeywords={u32, __u32, __be32, __le32,
  		u16, __u16, __be16, __le16,
	        u8,  __u8,  __be8,  __le8,
	        size_t, ssize_t}
}

% https://tex.stackexchange.com/questions/51645/
%  x86-64-assembler-language-dialect-for-the-listings-package
\lstdefinelanguage
   [x86_64]{Assembler}
   [x86masm]{Assembler}
   % with these extra keywords:
   {morekeywords={CDQE, CQO, CMPSQ, CMPXCHG16B, JRCXZ, LODSQ, MOVSXD,
                  POPFQ, PUSHFQ, SCASQ, STOSQ, IRETQ, RDTSCP, SWAPGS,
                  rax, rdx, rcx, rbx, rsi, rdi, rsp, rbp,
                  r8, r8d, r8w, r8b, r9, r9d, r9w, r9b}}

\usepackage{lettrine}
\newcommand{\initial}[1]{
\lettrine[lines=3,lhang=0.3,nindent=0em]{
\color{tumblue}
{\textsf{#1}}}{}}

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\usepackage{titling}
\newcommand{\HorRule}{\color{tumblue} \rule{\linewidth}{1pt}}

\pretitle{\thispagestyle{noheadings}\vspace{-30pt}
  \begin{flushleft} \HorRule \fontsize{25}{30} \usefont{OT1}{phv}{b}{n} \color{tumblue} \selectfont}

\title{JavaScript Technology Seminar 2017 Group 2: Unstructured Data - Report}

\posttitle{\par\end{flushleft}\vskip 0.5em}

\preauthor{\begin{flushleft}\large \lineskip 0.5em \usefont{OT1}{phv}{b}{sl}
  \color{tumblue}}

% Please leave this as it is for the 1st draft as our "peer-review"
% is supposed to take place anonymously (like in real life)
\author{Felix Schorer, Lukas Streit, Nikita Basargin, Anshul Sharma}

\postauthor{\footnotesize \usefont{OT1}{phv}{m}{sl} \color{Black} % Configuration for the institution name
, Technical University of Munich

\par\end{flushleft}\HorRule}
\date{}

%----------------------------------------------------------------------------------------
\makeatletter
\let\docauthor\@author
\makeatother
\makeatletter
\let\doctitle\@title
\makeatother


\fancypagestyle{headings}{
  \lhead{}
  \chead{}
  \rhead{\usefont{OT1}{phv}{m}{sc}\footnotesize \doctitle }

  % Footers
  \lfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize \docauthor }
  \cfoot{}
  \rfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize Page \thepage\ of \pageref{LastPage}}

  \renewcommand{\headrulewidth}{0.4pt}
  \renewcommand{\footrulewidth}{0.4pt}
}

\fancypagestyle{plain}{
  \fancyhf{}

  % Footers
  \lfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize \docauthor }
  \cfoot{}
  \rfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize Page \thepage\ of \pageref{LastPage}}

  \renewcommand{\headrulewidth}{0.0pt}
  \renewcommand{\footrulewidth}{0.4pt}
}
\lfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize \docauthor }
\cfoot{}
\rfoot{\usefont{OT1}{phv}{m}{sc}\footnotesize Page \thepage\ of \pageref{LastPage}}


\begin{document}

% Stop whining, \maketitle
\newcommand{\undefinedpagestyle}{}
\maketitle
\pagestyle{headings}

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

% The first character should be within \initial{}
\initial{T}\textbf{he goal of the \texttt{MusicConnectionMachine} project is to create a \enquote{social} network for classical composers, music pieces and musicians. 
There are a number of different relationships between them: 
piece $A$ was written by composer $B$, musicians $C$ and $D$ both liked genre $E$, composers $F$ and $G$ lived in the city $H$ at the year $I$, etc. 
Information is extracted from different internet sources. 
After processing and classification, the results are visualized and made open to public by integration into a popular online resource.}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section*{Sub-projects and teams}
The seminar initially had three main sub-projects: 
\emph{data aggregation}, \emph{information extraction} and \emph{visualization}. 
Two independent teams with four members each were assigned to each sub-project. 
During the seminar some structural changes were made. 
Some members actively worked on the interfaces and the new \emph{API} sub-project. 
Some teams were merged.


\section*{Unstructured data}
Our team was responsible for data aggregation on unstructured sources. 
Data from \emph{CommonCrawl} (CC) was used. 
This dataset is hosted on Amazon S3 and stores web page data from the last 7 years in different representations. 
We decided to work with text extractions (WET files) from the latest crawl. 
The biggest challenge was the size of the data. 
The March 2017 crawl produced 66500 WET files and more than 9 TB text extractions (compressed). 
Processing this amount of data on one machine would be too slow. 
Therefore we used multiple VMs hosted on Microsoft Azure for parallel processing.

A lot of data from CC is useless for us because it contains no information about classical music. 
This data must be quickly filtered and should not be passed to the groups dealing with information extraction. 
Otherwise it would significantly slow down the processing since natural language processing algorithms are quite slow. 
The group working on structured data sources provides us with a list of relevant terms. 
These terms are used for the filtering.


\section*{Data processing pipeline}
This section explains the basics of the data processing pipeline. 
In order to keep is simple, we assume that only one machine is doing the processing. 
Parallelization is described in the next section.

Apart from the command line arguments and environment variables we have two main inputs: 
terms provided by the structured data group and the actual data from CC. 
The terms are stored in the database. 
After loading, we remove those terms that are present on our blacklist. 
Afterwards we download WET files from CC one at a time, unpack them and start filtering.

We tried multiple filtering approaches such as naive string search, bloom filter, prefix tree and some combinations of those. 
Currently we use a prefix tree constructed from the relevant terms. 
For each web page in the WET file, we check how often relevant terms occur in the text. 
We use a heuristics: 
The web page is considered relevant only if $n$ distinct terms are found and there are at least $n^2$ total term occurrences.

As an additional filtering step we use language detection. 
Only web pages in English are passed. 
If a web page passes the filtering step, the whole content is stored inside a blob storage on Azure. 
The metadata (link to the blob, what and how many terms were found) are saved inside the database.


\section*{Parallel processing}
Each WET file is independent from others. 
This allows very high parallelism. 
On a single VM we have one master process and $m$ worker processes. 
The master loads terms from the DB, spawns the workers and assigns tasks to them. 
Each worker processes a single WET file at a time and informs the master once it is finished. 

TODO: shell scripts to spawn multiple VMs


\section*{Internal task distribution}




\section*{Timeline}
TODO

\subsection*{First steps}
TODO

\subsection*{Presentations}
TODO

\subsection*{Implementation}
TODO

\subsection*{Final steps}
TODO


\section*{Problems and feedback}
TODO



\section*{Conclusion}
TODO




%------------------------------------------------
%\subsection*{Subsection 1}
%1231232
%\section*{Section 2}
%123213
%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

% Feel free to use bibtex instead, this is just an example

%\begin{thebibliography}{99} % Bibliography - this is intentionally simple in this template
%
%\bibitem[Figueredo and Wolf, 2009]{Figueredo:2009dg}
%Figueredo, A.~J. and Wolf, P. S.~A. (2009).
%\newblock Assortative pairing and life history strategy - a cross-cultural
%  study.
%\newblock {\em Human Nature}, 20:317--330.
% 
%\end{thebibliography}

%----------------------------------------------------------------------------------------

\end{document}
